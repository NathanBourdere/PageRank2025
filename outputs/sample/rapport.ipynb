{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612b31dd",
   "metadata": {},
   "source": [
    "# Fichier consrtuisant les figures du rapport "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaac6c1",
   "metadata": {},
   "source": [
    "> R√©dig√© par Yannis CHUPIN et Nathan Bourdere Andreou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58712e5e",
   "metadata": {},
   "source": [
    "## 1. Test avec un √©chantillon √† 10% pr√©lev√© avec la m√©thode `\"vertex-cut\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecc44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Notebook d'analyse des r√©sultats PageRank\n",
    "G√©n√®re des visualisations et statistiques pour le rapport\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import glob\n",
    "\n",
    "# Configuration du style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# ==========================================\n",
    "# FONCTIONS UTILITAIRES\n",
    "# ==========================================\n",
    "\n",
    "def load_json_file(filepath):\n",
    "    \"\"\"Charge un fichier JSON\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            return json.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erreur lors du chargement de {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "def group_files_by_prefix(directory, extension=\"json\"):\n",
    "    \"\"\"\n",
    "    Groupe les fichiers par pr√©fixe (sans le dernier caract√®re)\n",
    "    Ex: file1.json, file2.json, file3.json -> groupe \"file\"\n",
    "    \"\"\"\n",
    "    files = list(Path(directory).rglob(f\"*.{extension}\"))\n",
    "    \n",
    "    groups = defaultdict(list)\n",
    "    for file in files:\n",
    "        # Retirer l'extension et le dernier caract√®re pour grouper\n",
    "        stem = file.stem  # nom sans extension\n",
    "        if len(stem) > 0:\n",
    "            # V√©rifier si le dernier caract√®re est un chiffre\n",
    "            if stem[-1].isdigit():\n",
    "                prefix = stem[:-1]  # Tout sauf le dernier caract√®re\n",
    "                groups[prefix].append(file)\n",
    "            else:\n",
    "                # Si pas de chiffre, consid√©rer comme un groupe √† un seul √©l√©ment\n",
    "                groups[stem].append(file)\n",
    "    \n",
    "    # Trier les fichiers dans chaque groupe\n",
    "    for prefix in groups:\n",
    "        groups[prefix].sort()\n",
    "    \n",
    "    return dict(groups)\n",
    "\n",
    "def load_metadata_group(filepaths):\n",
    "    \"\"\"Charge un groupe de fichiers metadata et retourne une liste de dicts\"\"\"\n",
    "    metadata_list = []\n",
    "    for filepath in filepaths:\n",
    "        data = load_json_file(filepath)\n",
    "        if data:\n",
    "            data['source_file'] = filepath.name\n",
    "            metadata_list.append(data)\n",
    "    return metadata_list\n",
    "\n",
    "def load_csv_with_fallback(filepath):\n",
    "    \"\"\"Charge un CSV avec gestion d'erreurs\"\"\"\n",
    "    try:\n",
    "        # Essayer avec header\n",
    "        df = pd.read_csv(filepath)\n",
    "        if df.shape[1] == 1:  # Pas de header d√©tect√©\n",
    "            df = pd.read_csv(filepath, header=None, names=['node', 'rank'])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erreur lors du chargement de {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==========================================\n",
    "# VISUALISATIONS\n",
    "# ==========================================\n",
    "\n",
    "def plot_execution_times(groups_data, title=\"Temps d'ex√©cution total\"):\n",
    "    \"\"\"\n",
    "    Boxplot des temps d'ex√©cution par groupe\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    data_for_plot = []\n",
    "    labels = []\n",
    "    \n",
    "    for group_name, metadata_list in groups_data.items():\n",
    "        times = [m['total_time_seconds'] for m in metadata_list]\n",
    "        data_for_plot.append(times)\n",
    "        labels.append(group_name)\n",
    "    \n",
    "    bp = ax.boxplot(data_for_plot, labels=labels, patch_artist=True,\n",
    "                    showmeans=True, meanline=True)\n",
    "    \n",
    "    # Colorier les boxplots\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(data_for_plot)))\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_ylabel('Temps (secondes)')\n",
    "    ax.set_xlabel('Configuration')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_iteration_times_candlestick(groups_data, title=\"Temps par it√©ration (Candlestick)\"):\n",
    "    \"\"\"\n",
    "    Candlestick chart pour les temps d'it√©ration\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(len(groups_data), 1, \n",
    "                             figsize=(14, 4 * len(groups_data)), \n",
    "                             squeeze=False)\n",
    "    \n",
    "    for idx, (group_name, metadata_list) in enumerate(groups_data.items()):\n",
    "        ax = axes[idx, 0]\n",
    "        \n",
    "        # Calculer statistiques par it√©ration\n",
    "        num_iterations = len(metadata_list[0]['iteration_times'])\n",
    "        iterations = range(1, num_iterations + 1)\n",
    "        \n",
    "        means = []\n",
    "        mins = []\n",
    "        maxs = []\n",
    "        q1s = []\n",
    "        q3s = []\n",
    "        \n",
    "        for i in range(num_iterations):\n",
    "            times = [m['iteration_times'][i] for m in metadata_list]\n",
    "            means.append(np.mean(times))\n",
    "            mins.append(np.min(times))\n",
    "            maxs.append(np.max(times))\n",
    "            q1s.append(np.percentile(times, 25))\n",
    "            q3s.append(np.percentile(times, 75))\n",
    "        \n",
    "        # Plot candlestick-like chart\n",
    "        for i, iter_num in enumerate(iterations):\n",
    "            # Ligne min-max\n",
    "            ax.plot([iter_num, iter_num], [mins[i], maxs[i]], \n",
    "                   'k-', linewidth=1, alpha=0.5)\n",
    "            # Bo√Æte Q1-Q3\n",
    "            height = q3s[i] - q1s[i]\n",
    "            ax.bar(iter_num, height, bottom=q1s[i], width=0.6, \n",
    "                  alpha=0.6, color='steelblue', edgecolor='black')\n",
    "            # Mean\n",
    "            ax.plot(iter_num, means[i], 'ro', markersize=6)\n",
    "        \n",
    "        ax.set_xlabel('It√©ration')\n",
    "        ax.set_ylabel('Temps (secondes)')\n",
    "        ax.set_title(f'{group_name} - Temps par it√©ration')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xticks(iterations)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_metrics_comparison(groups_data, title=\"Comparaison des m√©triques\"):\n",
    "    \"\"\"\n",
    "    Barplot comparant plusieurs m√©triques entre groupes\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    \n",
    "    metrics = [\n",
    "        ('num_nodes', 'Nombre de n≈ìuds', axes[0, 0]),\n",
    "        ('num_links', 'Nombre de liens', axes[0, 1]),\n",
    "        ('total_time_seconds', 'Temps total (s)', axes[1, 0]),\n",
    "        ('avg_iteration_time_seconds', 'Temps moyen/it√©ration (s)', axes[1, 1])\n",
    "    ]\n",
    "    \n",
    "    for metric_key, metric_label, ax in metrics:\n",
    "        data_for_plot = []\n",
    "        labels = []\n",
    "        errors = []\n",
    "        \n",
    "        for group_name, metadata_list in groups_data.items():\n",
    "            values = [m.get(metric_key, 0) for m in metadata_list]\n",
    "            data_for_plot.append(np.mean(values))\n",
    "            labels.append(group_name)\n",
    "            errors.append(np.std(values))\n",
    "        \n",
    "        x_pos = np.arange(len(labels))\n",
    "        bars = ax.bar(x_pos, data_for_plot, yerr=errors, \n",
    "                     capsize=5, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        \n",
    "        # Ajouter les valeurs sur les barres\n",
    "        for i, (bar, val) in enumerate(zip(bars, data_for_plot)):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                   f'{val:.2f}',\n",
    "                   ha='center', va='bottom', fontsize=9)\n",
    "        \n",
    "        ax.set_ylabel(metric_label)\n",
    "        ax.set_xlabel('Configuration')\n",
    "        ax.set_title(metric_label)\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14, y=1.00)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_top_pages(csv_groups, top_n=20, title=\"Top Pages par PageRank\"):\n",
    "    \"\"\"\n",
    "    Barplot horizontal des top pages pour chaque groupe\n",
    "    \"\"\"\n",
    "    num_groups = len(csv_groups)\n",
    "    fig, axes = plt.subplots(num_groups, 1, \n",
    "                             figsize=(14, 6 * num_groups),\n",
    "                             squeeze=False)\n",
    "    \n",
    "    for idx, (group_name, csv_files) in enumerate(csv_groups.items()):\n",
    "        ax = axes[idx, 0]\n",
    "        \n",
    "        # Charger et moyenner les ranks\n",
    "        all_ranks = []\n",
    "        for csv_file in csv_files:\n",
    "            df = load_csv_with_fallback(csv_file)\n",
    "            if df is not None:\n",
    "                all_ranks.append(df)\n",
    "        \n",
    "        if not all_ranks:\n",
    "            continue\n",
    "        \n",
    "        # Merger et calculer la moyenne des ranks\n",
    "        merged = pd.concat(all_ranks).groupby('node')['rank'].mean().reset_index()\n",
    "        merged = merged.sort_values('rank', ascending=False).head(top_n)\n",
    "        \n",
    "        # Plot\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(merged)))\n",
    "        bars = ax.barh(range(len(merged)), merged['rank'], color=colors)\n",
    "        ax.set_yticks(range(len(merged)))\n",
    "        ax.set_yticklabels(merged['node'], fontsize=9)\n",
    "        ax.set_xlabel('PageRank Score')\n",
    "        ax.set_title(f'{group_name} - Top {top_n} Pages')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # Ajouter les valeurs\n",
    "        for i, (bar, val) in enumerate(zip(bars, merged['rank'])):\n",
    "            width = bar.get_width()\n",
    "            ax.text(width, bar.get_y() + bar.get_height()/2.,\n",
    "                   f' {val:.4f}',\n",
    "                   ha='left', va='center', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def plot_rank_distribution(csv_groups, title=\"Distribution des PageRank\"):\n",
    "    \"\"\"\n",
    "    Histogrammes et violin plots de la distribution des ranks\n",
    "    \"\"\"\n",
    "    num_groups = len(csv_groups)\n",
    "    fig, axes = plt.subplots(num_groups, 2, \n",
    "                             figsize=(16, 5 * num_groups),\n",
    "                             squeeze=False)\n",
    "    \n",
    "    for idx, (group_name, csv_files) in enumerate(csv_groups.items()):\n",
    "        # Charger tous les ranks\n",
    "        all_ranks = []\n",
    "        for csv_file in csv_files:\n",
    "            df = load_csv_with_fallback(csv_file)\n",
    "            if df is not None:\n",
    "                all_ranks.extend(df['rank'].values)\n",
    "        \n",
    "        if not all_ranks:\n",
    "            continue\n",
    "        \n",
    "        # Histogram (√©chelle log)\n",
    "        ax1 = axes[idx, 0]\n",
    "        ax1.hist(all_ranks, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "        ax1.set_xlabel('PageRank Score')\n",
    "        ax1.set_ylabel('Fr√©quence')\n",
    "        ax1.set_title(f'{group_name} - Distribution (Histogramme)')\n",
    "        ax1.set_yscale('log')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Box plot\n",
    "        ax2 = axes[idx, 1]\n",
    "        bp = ax2.boxplot([all_ranks], vert=True, patch_artist=True,\n",
    "                         labels=[group_name], showmeans=True)\n",
    "        bp['boxes'][0].set_facecolor('lightblue')\n",
    "        ax2.set_ylabel('PageRank Score')\n",
    "        ax2.set_title(f'{group_name} - Distribution (BoxPlot)')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "def generate_summary_table(groups_data):\n",
    "    \"\"\"\n",
    "    G√©n√®re un DataFrame r√©sum√© avec statistiques par groupe\n",
    "    \"\"\"\n",
    "    summary = []\n",
    "    \n",
    "    for group_name, metadata_list in groups_data.items():\n",
    "        num_runs = len(metadata_list)\n",
    "        \n",
    "        times = [m['total_time_seconds'] for m in metadata_list]\n",
    "        nodes = [m['num_nodes'] for m in metadata_list]\n",
    "        links = [m['num_links'] for m in metadata_list]\n",
    "        avg_iter_times = [m['avg_iteration_time_seconds'] for m in metadata_list]\n",
    "        \n",
    "        summary.append({\n",
    "            'Configuration': group_name,\n",
    "            'Nombre de runs': num_runs,\n",
    "            'N≈ìuds': f\"{np.mean(nodes):.0f} ¬± {np.std(nodes):.0f}\",\n",
    "            'Liens': f\"{np.mean(links):.0f} ¬± {np.std(links):.0f}\",\n",
    "            'Temps total (s)': f\"{np.mean(times):.2f} ¬± {np.std(times):.2f}\",\n",
    "            'Temps moyen/iter (s)': f\"{np.mean(avg_iter_times):.2f} ¬± {np.std(avg_iter_times):.2f}\",\n",
    "            'Min temps (s)': f\"{np.min(times):.2f}\",\n",
    "            'Max temps (s)': f\"{np.max(times):.2f}\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cda73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "\n",
    "# R√©pertoire contenant les r√©sultats\n",
    "RESULTS_DIR = \"./sample/\"  # Adapter selon votre structure\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# MAIN EXECUTION\n",
    "# ==========================================\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ANALYSE DES R√âSULTATS PAGERANK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. D√©tecter et grouper les fichiers JSON\n",
    "    print(f\"\\nüìÇ Recherche des fichiers dans : {RESULTS_DIR}\")\n",
    "    json_groups = group_files_by_prefix(RESULTS_DIR, \"json\")\n",
    "    print(json_groups)\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(json_groups)} groupes de m√©tadonn√©es d√©tect√©s :\")\n",
    "    for group_name, files in json_groups.items():\n",
    "        print(f\"   - {group_name}: {len(files)} fichier(s)\")\n",
    "    \n",
    "    # 2. Charger les m√©tadonn√©es\n",
    "    print(\"\\nüìä Chargement des m√©tadonn√©es...\")\n",
    "    groups_data = {}\n",
    "    for group_name, files in json_groups.items():\n",
    "        metadata_list = load_metadata_group(files)\n",
    "        if metadata_list:\n",
    "            groups_data[group_name] = metadata_list\n",
    "            print(f\"   ‚úì {group_name}: {len(metadata_list)} run(s) charg√©(s)\")\n",
    "    \n",
    "    if not groups_data:\n",
    "        print(\"‚ùå Aucune m√©tadonn√©e valide trouv√©e !\")\n",
    "        return\n",
    "    \n",
    "    # 3. D√©tecter et grouper les fichiers CSV\n",
    "    print(f\"\\nüìÇ Recherche des CSV...\")\n",
    "    csv_groups = group_files_by_prefix(RESULTS_DIR, \"csv\")\n",
    "    print(f\"‚úÖ {len(csv_groups)} groupes de CSV d√©tect√©s\")\n",
    "    \n",
    "    # 4. G√©n√©rer le tableau r√©capitulatif\n",
    "    print(\"\\nüìã G√©n√©ration du tableau r√©capitulatif...\")\n",
    "    summary_df = generate_summary_table(groups_data)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"TABLEAU R√âCAPITULATIF\")\n",
    "    print(\"=\" * 60)\n",
    "    print(summary_df.to_string(index=False))\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 5. Sauvegarder le tableau\n",
    "    summary_df.to_csv(f\"{RESULTS_DIR}/summary_table.csv\", index=False)\n",
    "    print(f\"\\nüíæ Tableau sauvegard√© : {RESULTS_DIR}/summary_table.csv\")\n",
    "    \n",
    "    # 6. G√©n√©rer les visualisations\n",
    "    print(\"\\nüìä G√©n√©ration des visualisations...\")\n",
    "    \n",
    "    figures = []\n",
    "    \n",
    "    # Temps d'ex√©cution\n",
    "    fig1 = plot_execution_times(groups_data, \n",
    "                                title=\"Temps d'ex√©cution total par configuration\")\n",
    "    fig1.savefig(f\"{RESULTS_DIR}/plot_execution_times.png\", dpi=300, bbox_inches='tight')\n",
    "    figures.append((\"Temps d'ex√©cution\", \"plot_execution_times.png\"))\n",
    "    print(\"   ‚úì plot_execution_times.png\")\n",
    "    \n",
    "    # Candlestick des it√©rations\n",
    "    fig2 = plot_iteration_times_candlestick(groups_data,\n",
    "                                           title=\"Temps par it√©ration (Candlestick)\")\n",
    "    fig2.savefig(f\"{RESULTS_DIR}/plot_iteration_candlestick.png\", dpi=300, bbox_inches='tight')\n",
    "    figures.append((\"Temps par it√©ration\", \"plot_iteration_candlestick.png\"))\n",
    "    print(\"   ‚úì plot_iteration_candlestick.png\")\n",
    "    \n",
    "    # Comparaison des m√©triques\n",
    "    fig3 = plot_metrics_comparison(groups_data,\n",
    "                                  title=\"Comparaison des m√©triques entre configurations\")\n",
    "    fig3.savefig(f\"{RESULTS_DIR}/plot_metrics_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "    figures.append((\"M√©triques\", \"plot_metrics_comparison.png\"))\n",
    "    print(\"   ‚úì plot_metrics_comparison.png\")\n",
    "    \n",
    "    # Top pages (si CSV disponibles)\n",
    "    if csv_groups:\n",
    "        fig4 = plot_top_pages(csv_groups, top_n=20,\n",
    "                            title=\"Top 20 Pages par PageRank\")\n",
    "        fig4.savefig(f\"{RESULTS_DIR}/plot_top_pages.png\", dpi=300, bbox_inches='tight')\n",
    "        figures.append((\"Top Pages\", \"plot_top_pages.png\"))\n",
    "        print(\"   ‚úì plot_top_pages.png\")\n",
    "        \n",
    "        # Distribution des ranks\n",
    "        fig5 = plot_rank_distribution(csv_groups,\n",
    "                                     title=\"Distribution des scores PageRank\")\n",
    "        fig5.savefig(f\"{RESULTS_DIR}/plot_rank_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "        figures.append((\"Distribution\", \"plot_rank_distribution.png\"))\n",
    "        print(\"   ‚úì plot_rank_distribution.png\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ {len(figures)} visualisations g√©n√©r√©es dans : {RESULTS_DIR}/\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ANALYSE TERMIN√âE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Afficher les figures (optionnel, commenter si en mode batch)\n",
    "    # plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
